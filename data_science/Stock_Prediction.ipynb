{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbc62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83429bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"TCS1.csv\")  # Update the path to your CSV file\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181c00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4494 entries, 0 to 4493\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       4494 non-null   object \n",
      " 1   Open       4486 non-null   float64\n",
      " 2   High       4486 non-null   float64\n",
      " 3   Low        4486 non-null   float64\n",
      " 4   Close      4486 non-null   float64\n",
      " 5   Adj Close  4486 non-null   float64\n",
      " 6   Volume     4486 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 245.9+ KB\n",
      "None\n",
      "\n",
      "Data sample:\n",
      "         Date        Open        High         Low       Close  Adj Close  \\\n",
      "0  2004-08-27  122.800003  122.800003  119.820000  120.332497  88.088272   \n",
      "1  2004-08-30  121.237503  123.750000  120.625000  123.345001  90.293549   \n",
      "2  2004-08-31  123.312500  123.750000  122.000000  123.512497  90.416122   \n",
      "3  2004-09-01  123.750000  124.375000  122.949997  123.487503  90.397820   \n",
      "4  2004-09-02  123.737503  125.574997  123.250000  124.207497  90.924896   \n",
      "\n",
      "       Volume  \n",
      "0  30646000.0  \n",
      "1  24465208.0  \n",
      "2  21194656.0  \n",
      "3  19935544.0  \n",
      "4  21356352.0  \n"
     ]
    }
   ],
   "source": [
    "# Display information about the data\n",
    "print(\"Data information:\")\n",
    "print(data.info())\n",
    "print(\"\\nData sample:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c564300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with missing values:\n",
      "            Date  Open  High  Low  Close  Adj Close  Volume\n",
      "33    2004-10-13   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "1349  2010-02-06   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "1827  2012-01-07   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "1866  2012-03-03   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "1996  2012-09-08   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "2038  2012-11-11   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "2375  2014-03-22   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "2604  2015-02-28   NaN   NaN  NaN    NaN        NaN     NaN\n",
      "Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "print(\"\\nRows with missing values:\")\n",
    "print(data[data.isnull().any(axis=1)])\n",
    "data = data.dropna()\n",
    "print(\"Missing values handled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571ce1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data = data[['Date', 'Close']]\n",
    "data = data.set_index('Date')\n",
    "\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c378a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_size = int(len(data) * 0.8)\n",
    "test_size = len(data) - train_size\n",
    "train_data, test_data = data[:train_size, :], data[train_size:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a80fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for time series prediction\n",
    "def create_dataset(dataset, time_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_steps):\n",
    "        a = dataset[i:(i + time_steps), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_steps, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "                                     \n",
    "                                     \n",
    "time_steps = 10\n",
    "X_train, y_train = create_dataset(train_data, time_steps)\n",
    "X_test, y_test = create_dataset(test_data, time_steps)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(\"Data preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d11356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture built.\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units=50, return_sequences=True, input_shape=(1, time_steps)),\n",
    "    tf.keras.layers.LSTM(units=50),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "print(\"Model architecture built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98103f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compilation complete.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(\"Model compilation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c376ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Learning Curve Analysis...\n",
      "Training on subset of size: 1\n",
      "Model trained.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Train MSE: 0.0000, Test MSE: 0.2321\n",
      "Training on subset of size: 398\n",
      "Model trained.\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Train MSE: 0.0000, Test MSE: 0.0024\n",
      "Training on subset of size: 795\n",
      "Model trained.\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "Train MSE: 0.0000, Test MSE: 0.0132\n",
      "Training on subset of size: 1193\n",
      "Model trained.\n",
      "38/38 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "Train MSE: 0.0000, Test MSE: 0.0129\n",
      "Training on subset of size: 1590\n",
      "Model trained.\n",
      "50/50 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "Train MSE: 0.0000, Test MSE: 0.0090\n",
      "Training on subset of size: 1988\n"
     ]
    }
   ],
   "source": [
    "# Learning Curve Analysis\n",
    "train_sizes = np.linspace(1, len(X_train), 10, dtype=int)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "print(\"Starting Learning Curve Analysis...\")\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_subset, y_subset = X_train[:train_size], y_train[:train_size]\n",
    "    print(f\"Training on subset of size: {train_size}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_subset, y_subset, epochs=10, batch_size=16, verbose=0)\n",
    "    print(\"Model trained.\")\n",
    "    \n",
    "    # Predict on the training and testing subsets\n",
    "    train_pred = model.predict(X_subset)\n",
    "    test_pred = model.predict(X_test[:train_size])\n",
    "    \n",
    "    # Calculate errors and handle NaN values\n",
    "    train_mse = mean_squared_error(y_subset, train_pred)\n",
    "    test_mse = mean_squared_error(y_test[:train_size], test_pred)\n",
    "    \n",
    "    if not np.isnan(train_mse) and not np.isnan(test_mse):\n",
    "        train_errors.append(train_mse)\n",
    "        test_errors.append(test_mse)\n",
    "        print(f\"Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "print(\"Learning Curve Analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_errors, label='Training Error')\n",
    "plt.plot(train_sizes, test_errors, label='Testing Error')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-value Test\n",
    "y_test_pred = model.predict(X_test)\n",
    "p_values = f_regression(y_test_pred, y_test)[1]\n",
    "print(\"P-values for predictions:\", p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a989f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a significance threshold\n",
    "significance_threshold = 0.05\n",
    "\n",
    "# Check p-values and make a decision\n",
    "significant_predictions = np.where(p_values < significance_threshold)[0]\n",
    "non_significant_predictions = np.where(p_values >= significance_threshold)[0]\n",
    "\n",
    "\n",
    "for i in significant_predictions:\n",
    "    print(\"\\nSignificant predictions:\")\n",
    "    print(f\"Sample {i+1}: p-value = {p_values[i]:.4f}, Prediction = {y_test_pred[i][0]:.4f}\")\n",
    "\n",
    "\n",
    "for i in non_significant_predictions:\n",
    "    print(\"\\nNon-significant predictions:\")\n",
    "    print(f\"Sample {i+1}: p-value = {p_values[i]:.4f}, Prediction = {y_test_pred[i][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6d0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa8fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f5400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124f553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
